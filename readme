# GCP Data Engineering Pipeline - Cloud Composer Orchestration

End-to-end data pipeline orchestration using Cloud Composer (Airflow) for Employee data processing.

## Pipeline Flow

1. **Sensor**: Wait for CSV files to arrive in GCS landing bucket
2. **Raw Ingestion**: Dataflow jobs load CSV to BigQuery raw tables
3. **Staging**: Dataflow transforms raw data to staging tables
4. **Curation**: dbt models create final curated tables with SCD Type 2
5. **Archive**: Move processed files to archive folder

## Setup

### Prerequisites
- Cloud Composer environment running
- BigQuery datasets created (raw, staging, curation)
- GCS buckets created (landing, temp)
- Dataflow and dbt repositories prepared

### Deployment